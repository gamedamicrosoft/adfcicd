trigger:
- main

pool:
  #name: "Default"  # Replace "Default" with your self-hosted pool name
  vmImage: ubuntu-latest
  # DO NOT include vmImage

variables:
  - group: AZURE-CLI  # Link your Variable Group
  - name: RESOURCE_GROUP
    value: 'rg-experian-demo-01.'
  - name: ADF_NAME
    value: 'adf-experian-demo-1'
  - name: ASSETS_DIR
    value: '$(System.DefaultWorkingDirectory)/adf'
  - name: KEYVAULT_BASEURL
    value: 'https://gameda-kv1.vault.azure.net/'
  - name: DATABRICKS_URL
    value: 'adb-3006059123266207.7.azuredatabricks.net'
  - name: DATABRICKS_CLUSTER_ID
    value: '1211-053747-ss7i3ehb'
  - name: DATABRICKS_WORKSPACE_DIR
    value: "/repos/adf-databricks/notebooks"
  - name: DATABRICKS_TOKEN
    value: '$(DATABRICKS_TOKEN)'

stages:
  - stage: Deploy_Databricks_Notebooks
    displayName: "Deploy Notebooks to Databricks"
    jobs:
      - job: DeployNotebooks
        displayName: "Deploy Notebooks"
        pool:
          vmImage: ubuntu-latest
          #name: 'Default'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.x'
              addToPath: true
          - script: |
              python -m pip install --upgrade pip
              pip install databricks-cli

          - script: |
              echo "Configuring Databricks CLI..."
              mkdir -p ~/.databricks
              echo "[DEFAULT]" > ~/.databrickscfg
              echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
              echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg
            displayName: "Configure Databricks CLI"
            env:
              DATABRICKS_HOST: "https://$(DATABRICKS_URL)"
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

          - script: |
              echo "Testing Databricks CLI..."
              databricks workspace list
            displayName: "Test Databricks CLI"
            env:
              DATABRICKS_HOST: "https://$(DATABRICKS_URL)"
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)


