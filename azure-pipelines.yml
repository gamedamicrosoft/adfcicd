trigger:
- main

pool:
  #name: "Default"  # Replace "Default" with your self-hosted pool name
  vmImage: ubuntu-latest
  # DO NOT include vmImage

variables:
  - group: AZURE-CLI  # Link your Variable Group here
  RESOURCE_GROUP: 'rg-experian-demo-01.'
  ADF_NAME: 'adf-experian-demo-1'
  ASSETS_DIR: '$(System.DefaultWorkingDirectory)/adf'
  KEYVAULT_BASEURL: 'https://gameda-kv1.vault.azure.net/'
  DATABRICKS_URL: 'adb-3006059123266207.7.azuredatabricks.net'
  DATABRICKS_CLUSTER_ID: '1211-053747-ss7i3ehb'
  DATABRICKS_WORKSPACE_DIR: "/repos/adf-databricks/notebooks"
  DATABRICKS_TOKEN: '$(DATABRICKS_TOKEN)'

stages:
  - stage: Deploy_Databricks_Notebooks
    displayName: "Deploy Notebooks to Databricks"
    jobs:
      - job: DeployNotebooks
        displayName: "Deploy Notebooks"
        pool:
          vmImage: ubuntu-latest
          #name: 'Default'

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.x'
              addToPath: true
          - script: |
              python -m pip install --upgrade pip
              pip install databricks-cli
              databricks workspace -h
              echo "DATABRICKS_TOKEN length: ${#DATABRICKS_TOKEN}"  # Print length instead of value for security
              echo "DATABRICKS_TOKEN1 length: ${#DATABRICKS_TOKEN1}"  # Print length instead of value for security
              echo "***************Now actual command ************** DATABRICKS_HOST= ${DATABRICKS_HOST},   DATABRICKS_TOKEN = ${DATABRICKS_TOKEN} , DATABRICKS_TOKEN1 = ${DATABRICKS_TOKEN1}  "
              databricks workspace import_dir "${LOCAL_NOTEBOOKS_DIR}" "${DATABRICKS_WORKSPACE_DIR}" --overwrite
            displayName: "Run Databricks Deployment Script"
            env:
              LOCAL_NOTEBOOKS_DIR: "$(Build.SourcesDirectory)/databricks/notebooks"
              DATABRICKS_HOST: "https://$(DATABRICKS_URL)"  # Set in Azure DevOps as secret
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
              DATABRICKS_TOKEN1: "ABCD"