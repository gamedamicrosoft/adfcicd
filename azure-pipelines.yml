trigger:
  - main

pool:
  vmImage: ubuntu-latest

variables:
  - group: AZURE-CLI  # Link your Variable Group
  - name: RESOURCE_GROUP
    value: 'rg-experian-demo-01'
  - name: ADF_NAME
    value: 'adf-experian-demo-1'
  - name: ASSETS_DIR
    value: '$(System.DefaultWorkingDirectory)/adf'
  - name: KEYVAULT_BASEURL
    value: 'https://gameda-kv1.vault.azure.net/'
  - name: DATABRICKS_URL
    value: 'adb-5793926643470096.16.azuredatabricks.net'
  - name: DATABRICKS_CLUSTER_ID
    value: '1211-053747-ss7i3ehb'
  - name: DATABRICKS_WORKSPACE_DIR
    value: "/repos/adf-databricks/notebooks"

stages:
  - stage: Deploy_Databricks_Notebooks
    displayName: "Deploy Notebooks to Databricks"
    jobs:
      - job: DeployNotebooks
        displayName: "Deploy Notebooks"
        pool:
          vmImage: ubuntu-latest

        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '3.x'
              addToPath: true
            displayName: "Setup Python Environment"

          - script: |
              python -m pip install --upgrade pip
              pip install databricks-cli
            displayName: "Install Databricks CLI"

          - script: |
              echo "Configuring Databricks CLI..."
              mkdir -p ~/.databricks
              echo "[DEFAULT]" > ~/.databrickscfg
              echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
              echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg
              
              #echo "Validating the .databrickscfg file contents (host only):"
              #cat  ~/.databrickscfg
            displayName: "Configure Databricks CLI"
            env:
              DATABRICKS_HOST: "https://$(DATABRICKS_URL)"
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

          #- script: |
          #    echo "Debugging Token Length:"
          #    echo "Token length: ${#DATABRICKS_TOKEN}"
          #  displayName: "Check Token Length"
          #  env:
          #    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

          - script: |
              echo "Testing Databricks CLI..."
              databricks workspace import_dir "${LOCAL_NOTEBOOKS_DIR}" "${DATABRICKS_WORKSPACE_DIR}" --overwrite
            displayName: "Run Databricks Deployment Script"
            env:
              LOCAL_NOTEBOOKS_DIR: "$(Build.SourcesDirectory)/databricks/notebooks"
              DATABRICKS_HOST: "https://$(DATABRICKS_URL)"  # Set in Azure DevOps as secret
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
  - stage: Deploy_ADF
    displayName: 'Deploy Azure Data Factory Assets'
    jobs:
      - job: DeployADF
        displayName: 'Run ADF Deployment Script'
        pool:
          name: 'Default'

        steps:
          - script: |
              chmod +x ./scripts/deploy-adf.sh
              ./scripts/deploy-adf.sh
            displayName: 'Run deploy-adf.sh'
            env:
              RESOURCE_GROUP: $(RESOURCE_GROUP)
              ADF_NAME: $(ADF_NAME)
              ASSETS_DIR: $(ASSETS_DIR)
              AZURE_CLIENT_ID: $(AZURE_CLIENT_ID)
              AZURE_CLIENT_SECRET: $(AZURE_CLIENT_SECRET)
              AZURE_TENANT_ID: $(AZURE_TENANT_ID)
              AZURE_SUBSCRIPTION_ID: $(AZURE_SUBSCRIPTION_ID)
              KEYVAULT_BASEURL: $(KEYVAULT_BASEURL)
              DATABRICKS_URL: $(DATABRICKS_URL)
              DATABRICKS_CLUSTER_ID: $(DATABRICKS_CLUSTER_ID)